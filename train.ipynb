{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "411S21OTaKO7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "# torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyn_wRBja61l"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBfwOf7vaP3s"
      },
      "outputs": [],
      "source": [
        "# Setup the dataset\n",
        "!wget -nc  https://zenodo.org/record/5108846/files/masonry-images-sensors-2021.zip?download=1\n",
        "import zipfile\n",
        "import os\n",
        "if os.path.exists('data/')==False:\n",
        "  local_zip = 'masonry-images-sensors-2021.zip?download=1'\n",
        "  zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "  zip_ref.extractall('data/')\n",
        "  zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhQEGDzvaR4O",
        "outputId": "c9ff147a-bd99-4607-ef7f-a1f710b4eb8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "642 samples found for training set\n",
            "214 samples found for testing set\n",
            "90 samples found for real set\n"
          ]
        }
      ],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        Resize([100,100])\n",
        "        ])\n",
        "\n",
        "data_dir = 'data/masonry-images-sensors-2021'\n",
        "batch_size = 16\n",
        "\n",
        "train_set = datasets.ImageFolder(os.path.join(data_dir, 'train'),data_transforms)\n",
        "test_set = datasets.ImageFolder(os.path.join(data_dir, 'test'),data_transforms)\n",
        "real_set = datasets.ImageFolder(os.path.join(data_dir, 'real'), data_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "real_loader = torch.utils.data.DataLoader(real_set, batch_size=batch_size,shuffle=True, num_workers=2)\n",
        "\n",
        "classes_labels = ['uncracked', 'cracked']\n",
        "print('{} samples found for training set'.format(len(train_set)))\n",
        "print('{} samples found for testing set'.format(len(test_set)))\n",
        "print('{} samples found for real set'.format(len(real_set)))\n",
        "\n",
        "total_tr = len(train_set)\n",
        "total_rl = len(real_set)\n",
        "total_ts = len(test_set)\n",
        "tr_batches = len(train_loader)\n",
        "rl_batches = len(real_loader)\n",
        "ts_batches = len(test_loader)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eapiGLQ3aVl1"
      },
      "outputs": [],
      "source": [
        "# Download the pretrained model\n",
        "!pip install git+https://github.com/wielandbrendel/bag-of-local-features-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvSEOQ02DoxO"
      },
      "outputs": [],
      "source": [
        "import bagnets.pytorchnet\n",
        "pytorch_model = bagnets.pytorchnet.bagnet33(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0mXcM8paXw8"
      },
      "outputs": [],
      "source": [
        "import bagnets.pytorchnet\n",
        "pytorch_model = bagnets.pytorchnet.bagnet17(pretrained=True)\n",
        "for param in pytorch_model.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in pytorch_model.layer3.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in pytorch_model.layer2.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in pytorch_model.layer1.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0K7d-bzMabdl"
      },
      "outputs": [],
      "source": [
        "a = 1024\n",
        "b= 512\n",
        "class cls(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(cls, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.drp = nn.Dropout(0.2)\n",
        "    self.fc = nn.Linear(2048, a)        \n",
        "    self.fc2 = nn.Linear(a, b)\n",
        "    self.fc3 = nn.Linear(b,2)\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 2048*11*11)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc(x)   \n",
        "    x = self.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "pytorch_model.fc = cls()\n",
        "pytorch_model = pytorch_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WuCWk5lJTGw"
      },
      "outputs": [],
      "source": [
        "pytorch_model = pytorch_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr5p5mnJH1zh"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "summary(pytorch_model,(3,100,100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt7TvB25agfq"
      },
      "outputs": [],
      "source": [
        "model = pytorch_model\n",
        "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_acc = Accuracy()\n",
        "real_acc = Accuracy()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.004)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uo3TrJJCatcm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "pbar = tf.keras.utils.Progbar(target=tr_batches)\n",
        "\n",
        "def train_one_epoch():\n",
        "  running_loss = 0.0\n",
        "  accuracy = 0.0  \n",
        "  total_recl = []\n",
        "  total_prec = []\n",
        "  total_f1 = []\n",
        "  for i, data in enumerate(train_loader):\n",
        "    \n",
        "      \n",
        "      inputs, labels = data\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "      \n",
        "      loss = loss_fn(outputs, labels)\n",
        "      \n",
        "      \n",
        "      loss.backward()\n",
        "      optimizer.step()         \n",
        "      \n",
        "      acc = accuracy_score(preds.cpu(), labels.cpu())\n",
        "     \n",
        "      recl = recall_score(preds.cpu(),labels.cpu(),zero_division=0)\n",
        "\n",
        "      prec = precision_score(preds.cpu(),labels.cpu(),zero_division=0)\n",
        "      \n",
        "      f1 = f1_score(preds.cpu(),labels.cpu(),zero_division=0)\n",
        "      \n",
        "      accuracy += (preds == labels).sum().item()\n",
        "      \n",
        "      running_loss += loss.item() * labels.size(0)\n",
        "      \n",
        "      \n",
        "      total_recl.append(recl.item())\n",
        "      total_prec.append(prec.item())\n",
        "      total_f1.append(f1.item())\n",
        "      pbar.update(i+1, values=[(\"loss\",loss.item()),(\"acc\",acc),(\"Recall\",recl.item()),(\"Precision\",prec.item()),(\"F1\",f1.item())])\n",
        "  \n",
        "  total_loss = running_loss / (total_tr)\n",
        "  total_accuracy = (100 * accuracy / total_tr)\n",
        "  total_recl = np.mean(total_recl)\n",
        "  total_f1 =  np.mean(total_f1)\n",
        "  total_prec =  np.mean(total_prec)\n",
        "  return total_loss, total_accuracy, total_recl, total_prec, total_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JqDjNMalhGM"
      },
      "outputs": [],
      "source": [
        "def validation_step(model,val_loader,size):\n",
        "  pbar2 = tf.keras.utils.Progbar(target=len(val_loader))\n",
        "  model.train(False)\n",
        "  model.eval()\n",
        "  running_vloss = 0.0\n",
        "  vacc = 0.0\n",
        "  total_vrecl = []\n",
        "  total_vprec = []\n",
        "  total_vf1 = []\n",
        "  for i, vdata in enumerate(val_loader):\n",
        "        \n",
        "        vinputs, vlabels = vdata\n",
        "        vinputs = vinputs.to(device)\n",
        "        vlabels = vlabels.to(device)\n",
        "\n",
        "        voutputs = model(vinputs)\n",
        "        _, vpreds = torch.max(voutputs.data, 1)\n",
        "        vloss = loss_fn(voutputs, vlabels)\n",
        "        running_vloss += vloss * vlabels.size(0)\n",
        "        vacc += (vpreds == vlabels).sum().item()\n",
        "        real_acc = accuracy_score(vpreds.cpu(), vlabels.cpu())\n",
        "\n",
        "        vrecl = recall_score(vpreds.cpu(),vlabels.cpu(), zero_division=0)\n",
        "        vprec = precision_score(vpreds.cpu(),vlabels.cpu(), zero_division=0)\n",
        "        vf1 = f1_score(vpreds.cpu(),vlabels.cpu(), zero_division=0)\n",
        "\n",
        "        pbar2.update(i+1, values=[(\"loss\",vloss.item()),(\"acc\",real_acc),(\"Recall\",vrecl),(\"Precision\",vprec),(\"F1\",vf1)])\n",
        "\n",
        "        total_vrecl.append(vrecl)\n",
        "        total_vprec.append(vprec)\n",
        "        total_vf1.append(vf1)\n",
        "\n",
        "  total_vrecl = np.mean(total_vrecl)\n",
        "  total_vf1 =  np.mean(total_vf1)\n",
        "  total_vprec =  np.mean(total_vprec)\n",
        "  avg_vloss = running_vloss / (size)\n",
        "  avg_vacc = (100 * vacc / size)\n",
        "\n",
        "  return avg_vloss, avg_vacc, total_vprec, total_vrecl, total_vf1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nvnDvzelhBj"
      },
      "outputs": [],
      "source": [
        "best_t=0\n",
        "best_r=0\n",
        "def train_model(model,n_epochs=5):\n",
        "  \n",
        "  best_vacc = -100.\n",
        "  best_acc = -100.\n",
        "  epoch_number = 0\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{n_epochs}')\n",
        "    \n",
        "    model.train(True)\n",
        "    loss, acc, recl, prec, f1 = train_one_epoch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y43oGRURbIdY"
      },
      "outputs": [],
      "source": [
        "train_model(model,50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh1W-oHqixys"
      },
      "outputs": [],
      "source": [
        "val_loss = 0.0\n",
        "val_steps = 0\n",
        "total = 0\n",
        "correct = 0\n",
        "for i, data in enumerate(real_loader, 0):\n",
        "  with torch.no_grad():\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "    loss = loss_fn(outputs, labels)\n",
        "    val_loss += loss.cpu().numpy()\n",
        "    val_steps += 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
